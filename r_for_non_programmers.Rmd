---
title: "R for Non-Programmers: A Guide for Social Scientists"
author: "Daniel Dauber"
date: "`r Sys.Date()`"
description: "R for Non-Programmers: A Guide for Social Scientists is a springboard into the world of R without having to become a full-fledged R programmer or possess abundant knowledge in other programming languages. This book  guides you through the most common challenges in empirical research in the Social Sciences and offers practical and efficient solutions. Each chapter is dedicated to a common task we have to achieve to answer our research questions. In addition, it provides plenty of exercises and in-depth case studies based on actual data."
url: "http://danieldauber.com"
site: bookdown::bookdown_site
cover-image: "images/cover_art_icons/r4np_icon_white_bg_favicon.png"
favicon: "images/cover_art_icons/r4np_icon_favicon.svg"
github-repo: ddauber/r4np_book
documentclass: book
bibliography: book.bib
biblio-style: apa
link-citations: yes
always_allow_html: true
---

# Welcome {#welcome .unnumbered}

Placeholder



<!--chapter:end:index.Rmd-->

# Acknowledgements {#acknowledgments .unnumbered}

Special thanks are due to my wife, who supported me in so many ways to get this book completed. Also, I would like to thank my son, who patiently watched me sitting at the computer typing this book and encouraged me with hugs, smiles and kisses. Finally, Ida, my mother-in-law, deserves special thanks because she ensured I would not starve while passionately completing this mammoth project.

<!--chapter:end:00_acknowledgements.Rmd-->


# `Readme.` before you get started {#readme-before-you-get-started}

Placeholder


## A starting point and reference book {#a-starting-point-and-reference-book}
## Download the companion R package {#download-the-companion-r-package}
## A 'tidyverse' approach with some basic R {#a-tidyverse-approach-with-some-basic-r}
## Understanding the formatting of this book {#formatting-of-this-book}

<!--chapter:end:01_before_you_get_started.Rmd-->


# Why learn a programming language as a non-programmer? {#why-learn-a-programming-language-as-a-non-programmer}

Placeholder


## Learning new tools to analyse your data is always essential {#learning-new-tools-to-analyse-your-data-is-always-essential}
## Programming languages enhance your conceptual thinking {#programming-languages-enhance-your-conceptual-thinking}
## Programming languages allow you to look at your data from a different angle {#programming-languages-allow-you-to-look-at-your-data-from-a-different-angle}
## Learning any programming language will help you learn other programming languages. {#learning-any-programming-language-will-help-you-learn-other-programming-languages.}

<!--chapter:end:02_why_start_learning_a_programming_language.Rmd-->


# Setting up R and RStudio {#setting-up-r-and-rstudio}

Placeholder


## Installing R {#installing-r}
## Installing RStudio {#installing-rstudio}
## When you first start RStudio {#when-you-first-start-rstudio}
## Updating R and RStudio: Living at the pulse of innovation {#updating-r-and-rstudio}
## RStudio Cloud {#rstudio-cloud}

<!--chapter:end:03_setting_up_r_rstudio.Rmd-->


# The RStudio Interface {#the-rstudio-interface}

Placeholder


## The Console window {#the-console-window}
## The Source window {#the-source-window}
## The Environment / History / Connections / Tutorial window {#the-environment-history-connections-tutorial-window}
## The Files / Plots / Packages / Help / Viewer window {#the-files-plots-packages-help-viewer-window}
## Customise your user interface {#customise-your-user-interface}

<!--chapter:end:04_rstudio_interface.Rmd-->


# R Basics: The very fundamentals {#r-basics-the-very-fundamentals}

Placeholder


## Basic computations in R {#basic-computations-in-r}
## Assigning values to objects: '\<-' {#assigning-values-to-objects}
## Functions {#functions}
## R packages {#r-packages}
### Installing packages using `install.packages()` {#installing-packages-using-a-function}
### Installing packages via RStudio's package pane {#installing-packages-via-rstudio}
### Using R Packages {#using-r-packages}
## Coding etiquette {#coding-etiquette}
## Exercises {#exercises-chapter-5}

<!--chapter:end:05_r_basics.Rmd-->


# Starting your R projects {#starting-your-r-projects}

Placeholder


## Creating an R Project file {#creating-an-r-project}
## Organising your projects {#organising-your-projects}
## Creating an R Script {#creating-an-r-script}
## Using R Markdown {#r-markdown-and-r-notebooks}

<!--chapter:end:06_starting_r_projects.Rmd-->


# Data Wrangling and Cleaning {#data-wrangling}

Placeholder


## Import your data
### Import data from the *Files* pane
### Importing data from the *Environment* pane {#importing-data-from-the-environment-pane}
### Importing data using functions directly {#importing-data-using-functions}
## Inspecting your data {#inspecting-raw-data}
## Cleaning your column names: Call the `janitor` {#colnames-cleaning}
## Data types: What are they and how can you change them {#change-data-types}
## Handling factors {#handling-factors}
### Recoding factors {#recoding-factors}
### Reordering factor levels {#reordering-factor-levels}
## Dealing with missing data {#dealing-with-missing-data}
### Mapping missing data {#mapping-missing-data}
### Identifying patterns of missing data {#patterns-of-missing-data}
#### Missing completely at random (MCAR) {#missing-completetly-at-random-mcar}
#### Missing at random (MAR) {#missing-at-random-mar}
#### Missing not at random (MNAR) {#missing-not-at-random-mnar}
### Replacing or removing missing data {#replacing-removing-missing-data}
### Main takeaways regarding dealing with missing data {#main-takeaways-missing-data}
## Latent constructs and their reliability {#latent-constructs}
## Once you finished with data wrangling {#conclusion-data-wrangling}

<!--chapter:end:07_data_wrangling.Rmd-->


# Descriptive Statistics {#descriptive-statistics}

Placeholder


## Plotting in *R* with `ggplot2` {#plotting-in-r-with-ggplot2}
## Central tendency measures: Mean, Median, Mode {#central-tendency}
### Mean
### Median
### Mode {#mode}
## Indicators and visualisations to examine the spread of data {#spread-of-data}
### Boxplot: So much information in just one box
### Histogram: Do not mistake it as a bar plot
### Density plots: Your smooth histograms
### Violin plot: Your smooth boxplot
### QQ plot: A 'cute' plot to check for normality in your data {#qq-plot}
### Standard deviation: Your average deviation from the mean {#standard-deviation}
## Packages to compute descriptive statistics {#packages-for-descriptive-statistics}
### The `psych` package for descriptive statistics
### The `skimr` package for descriptive statistics

<!--chapter:end:08_descriptive_statistics.Rmd-->

# Sources of bias: Outliers, normality and other 'conundrums' {#sources-of-bias}

'*Bias'* in your analysis is hardly ever a good thing unless you are a qualitative researcher. Whether you consider it positive or negative, we have to be aware of issues preventing us from performing a specific type of analysis. All of the statistical computations discussed in the following chapters can easily be affected by different sources of bias. The lack of certain biases can be an assumption of particular statistical tests. Thus, violating these assumptions would imply that the analytical technique we use will produce wrong results, i.e. biased results. @field2013discovering summarises three main assumptions we have to consider:

-   Linearity and additivity,

-   Independence,

-   Normality, and

-   Homogeneity of variance, i.e. homoscedasticity.

Most *parametric tests* require that all assumptions are met. If this is not the case, we have to use alternative approaches, i.e. *non-parametric tests*. The distinction is essential since parametric and non-parametric tests are based on different computational methods, leading to different outcomes.

Lastly, @field2013discovering also mentions outliers as an important source of bias. Irrespective of whether your data fulfils the assumptions for parametric tests, outliers tend to be a significant problem. They usually lead to wrong results and, consequently, to misinterpretations of our findings. We will also cover how we can identify and handle such outliers in our data at the end of this chapter.

## Linearity and additivity {#additivity-and-linearity}

The assumption of linearity postulates that the relationship of variables represents a straight line and not a curve or any other shape. Figure \@ref(fig:linear-nonlinear-relationship) depicts examples of how two variables could be related to each other. Only the first one demonstrates a linear relationship, and all other plots would represent a violation for parametric tests.

```{r Linearity visualised, fig.cap="Examples of linear and non-linear relationship of two variables", label = "linear-nonlinear-relationships", echo=FALSE}
data <- tibble(x = seq(from = -10,
                       to = 10))

p1 <-
  data %>%
  ggplot(aes(x = x, y = x)) +
  geom_point() +
  geom_smooth(method = "lm",
              formula = y ~ x,
              se = FALSE,
              col = "red") +
  see::theme_modern() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("y = x")

p2 <-
  data %>%
  mutate(zz = x^2) %>%
  ggplot(aes(x = x, y = zz)) +
  geom_point() +
  geom_smooth(method = "lm",
              formula = y ~ poly(x, 5),
              se = FALSE,
              col = "red") +
  see::theme_modern() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("y = x^2")


p3 <-
  data %>%
  mutate(zz = x^3) %>%
  ggplot(aes(x = x, y = zz)) +
  geom_point() +
  geom_smooth(method = "lm",
              formula = y ~ poly(x, 5),
              se = FALSE,
              col = "red") +
  see::theme_modern() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("y = x^3")

p4 <-
  data %>%
  mutate(zz = x^4) %>%
  ggplot(aes(x = x, y = zz)) +
  geom_point() +
  geom_smooth(method = "lm",
              formula = y ~ poly(x, 5),
              se = FALSE,
              col = "red") +
  see::theme_modern() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("y = x^4")

# Put plots together
p1 + p2 + p3 + p4
```

Data visualisations are particularly useful to identify whether variables are related to each other in a linear fashion. The examples above were all created with `geom_point()`, which creates a dot plot that maps the relationship between two variables. In Chapter \@ref(correlations), we will look more closely at the relationship of two variables in the form of *correlations*, which measure the strength of a linear relationship between variables.

Additivity is given when the effects of all independent variables can be added up to obtain the total effect they have on a dependent variable. In other words, the effect that multiple variables have on another variable can be added up to reflect their total effect.

If we assume that we have a dependent variable $Y$ which is affected by other (independent) variables $X$, we could summarise additivity and linearity as a formula:

::: {#linearity_additivity-formula align="center"}
$Y = \beta_{1} * X_1 + \beta_{2} * X_{2} + ... + \beta_{n} * X_{n}$
:::

The $\beta$ (beta) stands for the degree of change in a variable $X$ causes in $Y$. Or, in simpler terms, $\beta$ reflects the impact an independent variable has on the dependent variable. We will return to this equation in Chapter \@ref(regression), where we create a linear model via regression.

## Independence

The notion of independence is an important one. It assumes that each observation in our dataset is independent of other observations. For example, imagine my wife Fiona and I take part in a study that asks us to rank movies by how much we like them. Each of us has to complete the ranking by ourselves, but since we both sit in the same living room, we start chatting about these movies. By doing so, we influence each other's rankings and might even agree on the same ranking. Thus, our scores are not independent from each other. On the other hand, suppose we were both sitting in our respective offices and rank these movies. In that case, the rankings could potentially still be very similar, but this time the observations are independent of each other.

There is no statistical measurement or plot that can tell us whether observations are independent or not. Ensuring independence is a matter of data collection and not data analysis. Thus, it depends on how you, for example, designed your experiment, or when and where you ask participants to complete a survey, etc. Still, this criterion should not be downplayed as being a 'soft' one, just because there is no statistical test, but should remain on your radar throughout the planning and data collection stage of your research.

## Normality {#normality}

We touched upon the notion of *'normality'* and *'normal distributions'* before in Chapter \@ref(spread-of-data) because it refers to the spread of our data. Figure \@ref(fig:normal-distribution2) should look familiar by now.

```{r Normal distribution 2, fig.cap="A normal distribution", echo=FALSE, label="normal-distribution2"}

data <- tribble(~x, -5, 5)

data %>% ggplot(aes(x)) +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = c(0), col = "red") +
  stat_function(fun = dnorm, n = 200, args = list(mean = 0, sd = 1.5)) +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) +
  theme_minimal() +
  xlab("mean/mode of \n x") +
  ylab("")
```

However, we have yet to understand why it is essential that our data follows a normal distribution. Most parametric tests are based on means. For example, if we want to compare two groups with each other, we would compute the mean for each of them and then see whether their means differ from each other in a significant way (see Chapter \@ref(comparing-groups). Of course, if our data is not very normally distributed, means are a poor reference point for most of the observations in this group. We already know that outliers heavily affect means, but even without outliers, the mean could be a poor choice. Let me provide some visual examples.

```{r Comparing two distributions and their means, echo=FALSE}
data <- tribble(
  ~income,
  1400,
  1500,
  1600,
  1650,
  1678,
  1685,
  1689,
  1700,
  1715,
  1800,
  1950
  )

p1 <-
  data %>%
  ggplot(aes(income)) +
  geom_density(bw = 80) +
  geom_vline(aes(xintercept = mean(income), color = "red")) +
  geom_text(aes(x = mean(income) - 15,
                y = 0.0002,
                label = "mean",
                angle = 90,
                color = "red"
                )) +
  geom_vline(aes(xintercept = median(income), color = "blue")) +
  geom_text(aes(x = median(income) + 15,
                y = 0.00024,
                label = "median",
                angle = 90,
                color = "blue"
                )) +
  ggtitle("Fig A: normal distribution") +
  theme(legend.position = "none",
        plot.title = element_text(size = 12))


data2 <- tribble(
  ~income,
  1500,
  1550,
  1600,
  1650,
  1678,
  1685,
  1689,
  1700,
  1715,
  1800,
  1950,
  2500,
  3500
  )

p2 <-
  data2 %>%
  ggplot(aes(income)) +
  geom_density(bw = 80) +
  geom_vline(aes(xintercept = mean(income), color = "red")) +
  geom_text(aes(x = mean(income) + 25,
                y = 0.0002,
                label = "mean",
                angle = 90,
                color = "red"
                )) +
  geom_vline(aes(xintercept = median(income), color = "blue")) +
  geom_text(aes(x = median(income) - 30,
                y = 0.00024,
                label = "median",
                angle = 90,
                color = "blue"
                )) +
  ggtitle("Fig B: No normal distribution") +
  theme(legend.position = "none",
        plot.title = element_text(size = 12))

data3 <- tribble(
  ~income,
  1100,
  1200,
  1150,
  1278,
  1300,
  1300,
  1695,
  1699,
  1715,
  1950,
  1700,
  1950
  )

p3 <-
  data3 %>%
  ggplot(aes(income)) +
  geom_density(bw = 80) +
  geom_vline(aes(xintercept = mean(income), color = "red")) +
  geom_text(aes(x = mean(income) - 15,
                y = 0.0002,
                label = "mean",
                angle = 90,
                color = "red"
                )) +
  geom_vline(aes(xintercept = median(income), color = "blue")) +
  geom_text(aes(x = median(income) + 15,
                y = 0.00024,
                label = "median",
                angle = 90,
                color = "blue"
                )) +
  ggtitle("Fig C: No normal distribution") +
  theme(legend.position = "none",
        plot.title = element_text(size = 12))

p1 + p2 + p3 + plot_spacer()
```

We notice that neither the median nor the mean by themselves is a reliable indicator for normality. Figure A and Figure C both show that the median and mean are almost identical, but only Figure A follows a normal distribution. The median and mean in Figure C are not reflective of the average observation in this dataset. Most scores lie below and above the mean/median. Therefore, when we analyse the normality of our data, we usually are not interested in the normality of a single variable but the normality of the sampling distribution. However, we cannot directly assess the sampling distribution in most cases. As such, we often revert to testing the normality of our data. There are also instances where we would not expect a normal distribution to exist. Consider the following plots:

```{r Normal distribution for two groups, fig.cap="Two normal distributions in one dataset", label = "two-normalities-groups", echo=FALSE}
data4 <- tribble(
  ~income,   ~gender,
  1400,      "male",
  1500,      "male",
  1600,      "male",
  1650,      "male",
  1678,      "male",
  1685,      "male",
  1689,      "male",
  1700,      "male",
  1715,      "male",
  1800,      "male",
  1950,      "male",
  1680,    "female",
  1800,    "female",
  1920,    "female",
  1980,    "female",
  2014,    "female",
  2022,    "female",
  2027,    "female",
  2040,    "female",
  2058,    "female",
  2160,    "female",
  2340,    "female"
  ) %>%
  mutate(gender = as_factor(gender))

p1 <-
  data4 %>%
  ggplot(aes(income)) +
  geom_density(bw = 80) +
  ggtitle("Bimodal distribution")

group_means <-
  data4 %>%
  group_by(gender) %>%
  summarise(mean = mean(income))

p2 <-
  data4 %>%
  ggplot(aes(income, group = gender, color = gender)) +
  geom_density(bw = 80) +
  ggtitle("Normal distribution for each group") +
  geom_vline(data = group_means,
             aes(xintercept = mean[1])) +
  geom_text(data = group_means,
            aes(x = mean[1] - 15,
                y = 0.00024,
                label = "mean",
                angle = 90
                )
            ) +
  geom_vline(data = group_means,
             aes(xintercept = mean[2])) +
    geom_text(data = group_means,
            aes(x = mean[2] - 15,
                y = 0.00024,
                label = "mean",
                angle = 90
                )
            )

p1 / p2
```

The first plot clearly shows that data is not normally distributed. If anything, it looks more like the back of a camel. The technical term for this distribution is called *'bimodal distribution'*. In cases where our data has even more peaks we consider it as a *'multimodal distribution'*. If we identify distributions that look remotely like this, we can assume that there must be another variable that helps explain why there are two peaks in our distribution. The plot below reveals that gender appears to play an important role. Drawing the distribution for each subset of our data reveals that `income` is now normally distributed for each group and has two different means. Thus, solely focusing on normal distributions for a single variable would not be meaningful if you do not consider the impact of other variables. If we think that `gender` plays an important role to understand `income` levels, we would have to expect that the distribution is not normal when looking at our data in its entirety.

Determining whether data is normally distributed can be challenging when only inspecting plots, e.g. histograms, density plots or QQ plots. Luckily, there is also a statistical method to test whether our data is normally distributed: *The Shapiro-Wilk test*. This test compares our distribution with a normal distribution (like in our plot) and tells us whether our distribution is **significantly different** from it. Thus, if the test is not significant, the distribution of our data is not significantly different from a normal distribution, or in simple terms: It is normally distributed. We can run the test in R as follows for the dataset that underpins Fig A above:

```{r Shapiro Wilk test, echo=TRUE}
shapiro.test(data$income)
```

This result confirms that the data is normally distributed, because it is not significantly different ($p > 0.05$). The chapter on correlations looks at significance and its meaning more thoroughly (see Chapter \@ref(correlations)).

In conclusion, the normality of data is an essential pre-test for any of our studies. If we violate the assumption of normality, we will have to fall back to non-parametric tests. However, this rule has two exceptions: *The Central Limit Theorem* and using *'robust'* measures of parametric tests.The Central Limit Theorem postulates that as our sample becomes larger, our sampling distribution becomes more and more normal around the mean of the underlying population. For example, @field2013discovering (p.54) refers to a sample of 30 as a common rule of thumb. As such, it is possible to assume normality for larger datasets even though our visualisation and the Shapiro-Wilk test tell us otherwise. The second exception is that many parametric tests offer a 'robust' alternative, often via *bootstrapping*. *Bootstrapping* refers to the process of subsampling your data, for example, 2000 times, and look at the average outcome. An example of bootstrapping is shown in Chapter \@ref(bootstrapped-regression).

Admittedly, this raises the question: Can I ignore normality and move on with my analysis if my sample is large enough or I use bootstrapping? In short: Yes. This fact probably also explains why we hardly ever find results from normality tests in journal publications since most Social Science research involves more than 30 participants. However, if you find yourself in a situation where the sample size is smaller, all of the above needs to be check and thoroughly considered. However, the sample size also has implications with regards to the power of your test/findings (see Chapter \@ref(power-analysis)). Ultimately, the answer to the above questions remains, unsatisfyingly: 'It depends'.

## Homogeneity of variance (homoscedasticity) {#homogeneity-of-variance}

The term *'variance'* should sound familiar, because we mentioned it in Chapter \@ref(standard-deviation) where we looked at the standard deviation derived from the variance.

*Homogeneity of variance* implies that the variance of, for example, two subsets of data, is equal or close to being equal. Let's look at how close the observed values are to the mean for the two groups identified in Figure \@ref(fig:two-normalities-groups).

```{r Homogeneity and no homogeneity of variance, echo=TRUE}
data4 %>%
  ggplot(aes(x = gender, y = income, col = gender)) +
  geom_jitter(width = 0.1) +
  geom_hline(yintercept = group_means$mean[1], color = "red") +
  geom_hline(yintercept = group_means$mean[2], color = "turquoise")
```

Judging by eye, we could argue that most values lie around the mean for each respective group. However, some observations are a bit further off. Still, using this visualisation, it is tough to judge whether the spread is about the same. However, boxplots can help with this, or even better, a boxplot reflected by a bar. The package `ggdist` has an excellent plotting function called `stat_interval()`, which allows us to show a boxplot in the form of a bar.

```{r Homogeneity and no homogeneity of variance alternative visualisation, echo=TRUE}
data4 %>%
  ggplot(aes(x = gender, y = income, group = gender)) +
  ggdist::stat_interval(aes(y = income),
                        .width = c(0.25, 0.5, 0.75, 1)) +

  # Let's add some nice complementary colours
  scale_color_manual(values = c("#4D87B3", "#A1D6FF", "#FFDAA1", "#B3915F"))
```

If we compare the bars, we can tell that the variance in both groups looks very similar, i.e. the length of the bars appear to be about the same height. Furthermore, if we compare the IQR for both groups, we find that they are quite close to each other.

```{r IQR for both groups, echo=TRUE}
data4 %>%
  group_by(gender) %>%
  summarise(iqr = IQR(income))
```

However, to test whether the variance between these two groups is truly similar or different, we have to perform a *Levene's test*. The Levene's test follows a similar logic as the Shapiro-Wilk test. If the test is significant, i.e. $p < 0.05$, we have to assume that the variances between these groups are significantly different from each other. However, if the test is not significant, then the variances are similar, and we can proceed with a parametric test - assuming other assumptions are not violated. The interpretation of this test follows the one for the Shapiro-Wilk test. To compute the Levene's test we can use the function `leveneTest()` from the `car` package. However, instead of using `,` to separate the two variables, this function expects a formula, which is denotated by a `~`. We will cover formulas in the coming chapters.

```{r Levenes test, echo=TRUE, warning=FALSE}
car::leveneTest(gep$age ~ gep$gender)
```

The Levene's test shows that our variances are similar and not different from each other because $p > 0.05$. This is good news if we wanted to continue and perform a group comparison, like in Chapter \@ref(comparing-groups).

## Outliers and how to deal with them {#dealing-with-outliers}

In Chapter \@ref(descriptive-statistics), I referred to outliers many times but never eluded to the aspects of handling them. Dealing with outliers is similar to dealing with missing data. However, it is not quite as straightforward as one might think.

In a first step, we need to determine which values count as an outlier. @aguinis2013best reviewed 232 journal articles and found that scholars had defined outliers in 14 different ways, used 39 different techniques to detect them and applied 20 different strategies to handle them. It would be impossible to work through all these options in this book. However, I want to offer two options that have been frequently considered in publications in the field of Social Sciences:

-   The standard deviation (SD), and

-   The inter-quartile range (IQR).

### Detecting outliers using the standard deviation {#ouliers-standard_deviation}

A very frequently used approach to detecting outliers is the use of the standard deviation. Usually, scholars use multiples of the standard deviation to determine thresholds. For example, a value that lies 3 standard deviations above or below the mean could be categorised as an outlier. Unfortunately, there is quite some variability regarding how many multiples of the standard deviation counts as an outlier. Some authors might use `3`, and others might settle for `2` (see also @leys2013detecting). Let's stick with the definition of `3` standard deviations to get us started. We can revisit our previous plot regarding `runtime_min` (See Figure \@ref(fig:runtime-movies-deviation) and add lines that show the thresholds above and below the mean.

```{r Outlier detection usind 3 sd, echo=TRUE}
# Compute the mean and the thresholds
runtime_mean <- mean(imdb_top_250$runtime_min)
sd_upper <- runtime_mean + 3 * sd(imdb_top_250$runtime_min)
sd_lower <- runtime_mean - 3 * sd(imdb_top_250$runtime_min)

# Create our base plot
outlier_plot <-
  imdb_top_250 %>%
  select(title, runtime_min) %>%
  ggplot(aes(x = reorder(title, runtime_min), y = runtime_min)) +
  geom_point(shape = 124) +
  geom_hline(aes(yintercept = runtime_mean, col = "red"), show.legend = FALSE) +

  theme(axis.text.x = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank()
        ) +
  ylab("run time") +
  xlab("movies") +
  
  # Add the thresholds
  geom_hline(aes(yintercept = sd_upper, col = "blue"), show.legend = FALSE) +
  geom_hline(aes(yintercept = sd_lower, col = "blue"), show.legend = FALSE)
```

The results suggest that only very few outliers would be detected if we chose these thresholds. Especially `Sherlock Jr.`, the shortest movie in our dataset, would not classify as an outlier. How about we choose 2 standard deviations instead?

```{r Outlier detection usind 2 sd, echo=TRUE}
# Compute the mean and standard deviation
runtime_mean <- mean(imdb_top_250$runtime_min)
sd_upper <- runtime_mean + 2 * sd(imdb_top_250$runtime_min)
d_lower <- runtime_mean - 2 * sd(imdb_top_250$runtime_min)

# Create our plot
imdb_top_250 %>%
  select(title, runtime_min) %>%
  ggplot(aes(x = reorder(title, runtime_min), y = runtime_min)) +
  geom_point(shape = 124) +
  geom_hline(aes(yintercept = runtime_mean, col = "red"),
             show.legend = FALSE) +
  geom_hline(aes(yintercept = sd_upper, col = "blue"),
             show.legend = FALSE) +
  geom_hline(aes(yintercept = sd_lower, col = "blue"),
             show.legend = FALSE) +

  theme(axis.text.x = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank()
        ) +
  ylab("run time") +
  xlab("movies")

```

As we would expect, we identify some more movies as being outliers, but the shortest movie would still not be classified as an outlier. It certainly feels somewhat arbitrary to choose a threshold of our liking. Despite its popularity, there are additional problems with this approach:

-   outliers affect our mean and standard deviation too,

-   since we use the mean, we assume that our data is normally distributed, and

-   in smaller samples, this approach might result in not identifying outliers at all (despite their presence) (@leys2013detecting, p. 764)

@leys2013detecting propose an alternative approach because medians are much less vulnerable to outliers than the mean. Similarly to the standard deviation, it is possible to calculate thresholds using the *median absolute deviation* (MAD). Best of all, the function `mad()` in *R* does this automatically for us. @leys2013detecting suggest using `2.5` times the MAD as a threshold. However, if we want to compare how well this option performs against the standard deviation, we could use `3` as well.

```{r Outlier detection via median MAD3, echo=TRUE}
# Compute the median and thresholds
runtime_median <- median(imdb_top_250$runtime_min)
mad_upper <- runtime_median + 3 * mad(imdb_top_250$runtime_min)
mad_lower <- runtime_median - 3 * mad(imdb_top_250$runtime_min)

# Create our plot
imdb_top_250 %>%
  select(title, runtime_min) %>%
  ggplot(aes(x = reorder(title, runtime_min), y = runtime_min)) +
  geom_point(shape = 124) +
  geom_hline(aes(yintercept = runtime_median, col = "red"),
             show.legend = FALSE) +
  geom_hline(aes(yintercept = mad_upper, col = "blue"),
             show.legend = FALSE) +
  geom_hline(aes(yintercept = mad_lower, col = "blue"),
             show.legend = FALSE) +

  theme(axis.text.x = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank()
        ) +
  ylab("run time") +
  xlab("movies")
```

Compared to our previous results, we notice that the median approach was much better in detecting outliers at the upper range of `runtim_min`. Because the median is not affected so much by the five-hour-long movie, the results have improved. Still, we would not classify the outlier at the bottom for the shortest film in the data. If we chose the criterion of `2.5 * MAD`, we would also get this outlier (see Figure \@ref(fig:MAD2-outlier-detection)).

```{r Outlier detection via median MAD2, echo=FALSE, fig.cap="Outlier detection via MAD using `2.5 * MAD` as a threshold", label = "MAD2-outlier-detection"}
# Compute the median and thresholds
runtime_median <- median(imdb_top_250$runtime_min)
mad_upper <- runtime_median + 2.5 * mad(imdb_top_250$runtime_min)
mad_lower <- runtime_median - 2.5 * mad(imdb_top_250$runtime_min)

# Create our plot
imdb_top_250 %>%
  select(title, runtime_min) %>%
  ggplot(aes(x = reorder(title, runtime_min), y = runtime_min)) +
  geom_point(shape = 124) +
  geom_hline(aes(yintercept = runtime_median, col = "red"),
             show.legend = FALSE) +
  geom_hline(aes(yintercept = mad_upper, col = "blue"),
             show.legend = FALSE) +
  geom_hline(aes(yintercept = mad_lower, col = "blue"),
             show.legend = FALSE) +

  theme(axis.text.x = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank()
        ) +
  ylab("run time") +
  xlab("movies")
```

Which approach to choose very much depends on the nature of your data. One consideration could be that if the median and the mean of a variable are dissimilar, choosing the median might be the better option. However, we should not forget that the outliers we definitely need to identify are those that will affect the mean. Hence, it appears that in many cases the median could be the better choice. Luckily there is yet another methods that is highly popular and based on two quartiles (rather the one, i.e. the median).

### Detecting outliers using the interquartile range (IQR) {#outliers-iqr}

Another approach to classifying outliers is the use of the *interquartile range (IQR)*. The IQR is used in boxplots and creates the dots at its ends to indicate any outliers. This approach is straightforward to implement because the computation of the IQR is simple:

::: {#iqr-formula align="center"}
$IQR = Q_{3}-Q_{1}$
:::

Therefore, we can create new thresholds for the detection of outliers. For IQR, it is common to use $\pm 1.5 * IQR$ as the lower and upper thresholds measured from $Q_1$ and $Q_3$ respectively. To compute the quartiles we can use the function `quantile()`, which returns $Minimum, Q_1, Q_2, Q_3, and\ Q_4$

```{r IQR as a threshold for outliers, echo=TRUE}
# Compute the quartiles
(runtime_quantiles <- quantile(imdb_top_250$runtime_min))

# Compute the thresholds
iqr_upper <- runtime_quantiles[4] + 1.5 * IQR(imdb_top_250$runtime_min)
iqr_lower <- runtime_quantiles[2] - 1.5 * IQR(imdb_top_250$runtime_min)

# Create our plot
imdb_top_250 %>%
  select(title, runtime_min) %>%
  ggplot(aes(x = reorder(title, runtime_min), y = runtime_min)) +
  geom_point(shape = 124) +
  geom_hline(aes(yintercept = runtime_median, col = "red"),
             show.legend = FALSE) +
  geom_hline(aes(yintercept = iqr_upper, col = "blue"),
             show.legend = FALSE) +
  geom_hline(aes(yintercept = iqr_lower, col = "blue"),
             show.legend = FALSE) +

  theme(axis.text.x = element_blank(),
        panel.grid.major = element_blank(),
        panel.background = element_blank()
        ) +
  ylab("run time") +
  xlab("movies")
```

As we can tell, the IQR method detects about the same outliers for our data as the median absolute deviation (MAD) approach. The outliers we find here are the same as shown in Figure \@ref(fig:a-boxplot).

For our data, I would argue that the IQR and MAD method by @leys2013detecting produced the 'best' selection of outliers. However, we have to acknowledge that these classifications will always be subjective because how we position the thresholds depends on the researcher's choice. Still, the computation is standardised, and we can plausibly explain the process of identifying outliers.

### Removing or replacing outliers {#removing-or-replacing-outliers}

Now that we have identified our outliers, we are confronted with the question of what we should do with them. Like missing data (see Chapter \@ref(dealing-with-missing-data)), we can either remove them or replace them with other values. While removal is a relatively simple task, replacing it with other 'reasonable' values implies finding techniques to create such values. As you may remember, we were confronted with a similar problem before when we looked into missing data (Chapter \@ref(dealing-with-missing-data). The same techniques, especially multiple imputation [see @cousineau2010outliers], can also be used for such scenarios.

Irrespective of whether we remove or replace outliers, we somehow need to single them out of the crowd. Since the IQR strategy worked well for our data, we can use the thresholds we defined before, i.e. `iqr_upper` and `iqr_lower`. Therefore, an observation (i.e. a movie) is considered an outlier if

-   its value lies above `iqr_upper`, or

-   its value lies below `iqr_lower`

It becomes clear that we somehow need to define a condition because if it is an outlier, it should be labelled as one. Ideally, we want a new column in our dataset which indicates whether a movie is an outlier (i.e. outlier = TRUE) or not (outlier = FALSE). R offers a way for us to express such conditions with the function `ifelse()`. It has the following structure:

::: {#ifelse-function align="center"}
`ifelse(condition, TRUE, FALSE)`
:::

Let's formulate a sentence that describes our scenario as an `ifelse()` function:

-   If a movie's `runtime_min` is longer than `iqr_upper`, [or]{.ul}

-   if a movie's `runtime_min` is lower than `iqr_lower`,

-   classify this movie as an outlier (i.e. `TRUE`),

-   otherwise, classify this movie as not being an outlier (i.e. `FALSE`).

We already know from Chapter \@ref(basic-computations-in-r) how to use logical and arithmetic operators. All we have to do is put them together in one function call.

```{r Classifying outliers with IQR, echo=TRUE}
imdb_top_250 <-
  imdb_top_250 %>%
  mutate(outlier = ifelse(runtime_min > iqr_upper |
                            runtime_min < iqr_lower,
                          TRUE, FALSE))
```

Since we have a classification, we can more thoroughly inspect our outliers and see which movies are the ones that are lying outside our defined norm. We can `arrange()` them by `runtime_min`.

```{r List the outliers, echo=TRUE}
imdb_top_250 %>%
  filter(outlier == "TRUE") %>%
  select(title, runtime_min, outlier) %>%
  arrange(runtime_min)
```

The list of movies contains some of the most iconic Hollywood films ever shown on screen. However, I think we can agree that most of them are truly outside the norm of regular movies, not just in terms of runtime.

From here, it is simple to remove these movies (i.e. keep the movies that are not outliers) or set their values to `NA`. If we replace the values with `NA`, we can continue with one of the techniques demonstrated for missing values in Chapter \@ref(dealing-with-missing-data). Both approaches are shown in the following code chunk.

```{r Remove and replacing outliers, echo=TRUE, results='hide'}
# Keep all movies that are not outliers
imdb_top_250 %>%
  filter(outlier == "FALSE") %>%
  select(title, outlier)

# Replace values with NA
imdb_top_250 %>%
  mutate(runtime_min = replace(runtime_min, outlier == "TRUE", NA)) %>%
  select(title, runtime_min)
```

The `replace()` function is very intuitive to use. It first needs to know where you want to replace a value (`runtime_min`), then what the condition for replacing is (`outlier == "TRUE"`), and lastly, which value should be put instead of the original one (`NA`).

As you hopefully noticed, understanding your data requires some effort, but it is important to know your data well before proceeding to any further analysis. You can experiment with different data visualisations and design them in a way that best reflects the message you want to get across. For example, because we have now a separate variable that classifies outliers, we can do more with our data visualisation than before and dress it up more nicely.

```{r Plot with outliers formatted differently, echo=TRUE}
imdb_top_250 %>%
  ggplot(aes(x = reorder(genre_01, runtime_min),
             y = runtime_min,
             coloutlier,
             shape = outlier)
         ) +
  geom_point(size = 1) +
  theme(panel.background = element_blank()) +
  coord_flip()

```

To round things off, let me share with you one more visualisation, which demonstrates that outliers might also have to be defined based on specific groupings of your data, e.g. movie genres. Thus, it might be essential to consider outliers in light of sub-samples of your data rather than the entire dataset.

```{r Final plot to show outliers, echo=TRUE, warning=FALSE}
colour_pal <- wesanderson::wes_palette("Darjeeling1", 11, type = "continuous")

imdb_top_250 %>%
  ggplot(aes(x = reorder(genre_01, runtime_min),
             y = runtime_min,
             col = genre_01)
         ) +
  geom_boxplot(alpha = 0,
               show.legend = FALSE) +
  geom_jitter(width = 0.1,
              size = 0.5,
              alpha = 0.5,
              show.legend = FALSE
              ) +
  scale_color_manual(values = colour_pal) +
  coord_flip() +
  theme(panel.background = element_blank()) +
  xlab("runtime") +
  ylab("Genre") +
  ggtitle("Distribution of movie runtimes by genre")
```

<!--chapter:end:09_sources_of_bias.Rmd-->


# Correlations {#correlations}

Placeholder


## Plotting correlations {#plotting-correlations}
## Computing correlations
## Significance: A way to help you judge your findings {#significance}
## Limitations of correlations {#limitations-of-correlations}
### Correlations are not causal relationships {#correlations-are-not-causal-relationships}
### Correlations can be spurious {#correlations-can-be-spurious}
### Simpson's Paradox: When correlations betray you {#simpsons-paradox}

<!--chapter:end:10_correlations.Rmd-->


# Power: You either have it or you don't {#power-analysis}

Placeholder


## Ingredients to achieve the power you deserve {#ingredients-power-analysis}
## Computing power {#computing-power}
## Plotting power {#plotting-power}
## Concluding remarks about power analysis

<!--chapter:end:11_power_analysis.Rmd-->


# Comparing groups {#comparing-groups}

Placeholder


## Comparability: Apples vs Oranges {#comparability-apples-vs-oranges}
## Comparing two groups {#comparing-two-groups}
### Two unpaired groups {#two-unpaired-groups}
### Two paired groups {#two-paired-groups}
## Comparing more than two groups {#comparing-more-than-two-groups}
### Multiple unpaired groups {#multiple-unpaired-groups}
### Multiple paired groups {#multiple-paired-groups}
#### Testing the assumption of sphericity {#sphericity}
#### Visualising and computing multiple paired group comparisons {#visualising-computing-multiple-paired-group-comparisons}
## Comparing groups based on factors: Contingency tables {#chi-squared-test}
### Unpaired groups of categorical variables {#unpaired-groups-categorical-variables}
### Paired groups of categorical variables {#paired-groups-categorical-variables}
### A final remark about comparing groups based on categorical data
## Reviewing group comparisons {#reviewing-group-comparisons}

<!--chapter:end:12_group_comparison.Rmd-->


# Regression: Creating models to predict future observations {#regression}

Placeholder


## Single linear regression {#single-linear-regression}
### Fitting a regression model by hand, i.e. trial and error {#fitting-a-regression-model-by-hand}
### Fitting a regression model computationally {#fitting-a-regression-model-computationally}
## Multiple regression {#multiple-regression}
### Outliers in multiple regressions {#outliers-in-multiple-regressions}
#### Outliers in the dependent variable {#outliers-in-the-dependent-variable}
#### Outliers in the independent variables {#outliers-in-the-independent-variables}
#### Outlier detection considering the entire model: Global measures {#outlier-detection-global-measures}
#### Outlier detection considering the entire model: Specific measures {#outlier-detection-specific-measures}
#### Reviewing the outliers {#reviewing-the-outliers}
### Standardised beta ($\beta$) vs. unstandardised beta ($B$) {#standardised-beta-vs-unstandardised-beta}
### Multicollinearity: The dilemma of highly correlated independent variables
## Hierarchical regression
### Regressions with control variables
### Moderated regression
### Centering predictors: Making $\beta$s more interpretable {#centering-predictors}
## Other regression models: Alternatives to OLS

<!--chapter:end:13_regressions.Rmd-->


# Mixed-methods research: Analysing qualitative in R {#mixed-methods-research}

Placeholder


## The tidy process of working with textual data {#tidy-process-for-textual-data}
## Stop words: Removing noise in the data
## N-grams: Exploring correlations of words {#n-grams}
## Exploring more mixed-methods research approaches in R

<!--chapter:end:14_mixed_methods.Rmd-->


# Where to go from here: The next steps in your R journey {#next-steps}

Placeholder


## GitHub: A Gateway to even more ingenious R packages
## Books to read and expand your knowledge
## Engage in regular online readings about R
## Join the Twitter community and hone your skills

<!--chapter:end:15_next_steps.Rmd-->


# Case studies: In-depth analysis

Placeholder


## Bootstrapped regression with multi-level control variable and moderation {#bootstrapped-regression}

<!--chapter:end:16_case_studies.Rmd-->

# Epilogue {#epilogue .unnumbered}

Congratulations! You made it through the book, or you started reading it from the back. Either way, I hope that spending your valuable time with this book was/is enjoyable, insightful and hopefully helpful in whatever grand questions you intend to answer through your research.

For my part, it has been a very enjoyable experience to put these materials together for those who need them. I also learned several new aspects about R I did not know before, for example, how to use bookdown to write this book. My biggest hope is to convince more researchers in the Social Sciences to try something new that can enrich their work. Whether you decide to adopt R for all your work, intend to move on to other languages like Python, or give up on it entirely, it does not matter. At least you tried, and you are more knowledgeable. Whenever we learn something new, it requires us to push ourselves out of our comfort zone, and I hope this book helped with that.

Whichever path you choose, I hope your research will have an impact, which, of course, does not depend on the tools you use.

<!--chapter:end:16_epilogue.Rmd-->


# Case studies: In-depth analysis

Placeholder


## Bootstrapped regression with multi-level control variable and moderation {#case-study-bootstrapped-regression}

<!--chapter:end:17_case_studies.Rmd-->


# Appendix {.unnumbered}

Placeholder


## Comparing two unpaired groups

<!--chapter:end:99_appendix.Rmd-->


# Exercises: Solutions {#exercises-solutions}

Placeholder


## Solutions for 5.6 {#exercises-solutions-5}

<!--chapter:end:99_exercise_solutions.Rmd-->

